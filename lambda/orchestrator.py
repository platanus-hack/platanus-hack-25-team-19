import json
import logging
import os
import uuid
import boto3
from datetime import datetime
from typing import Dict, Any, List
from shared.anthropic import Anthropic, ConversationMessage

def get_organization_registry() -> List[Dict[str, Any]]:
    """Get organization data with fallback for when module is not available."""
    try:
        from shared.organization_diagram import get_organization_data
        return get_organization_data()
    except ImportError:
        logger.warning("Organization diagram module not found, using empty data")
        return []

logger = logging.getLogger()
logger.setLevel(logging.INFO)

# --- ANTHROPIC CONFIGURATION ---
ANTHROPIC_API_KEY = os.environ.get('ANTHROPIC_API_KEY', '')

# Initialize AWS clients
dynamodb = boto3.resource("dynamodb")
sqs = boto3.client("sqs")

# Initialize Anthropic client
anthropic = Anthropic(api_key=ANTHROPIC_API_KEY)

# Get environment variables
JOBS_TABLE_NAME = os.environ["JOBS_TABLE_NAME"]
SLACK_QUEUE_URL = os.environ["SLACK_QUEUE_URL"]
MARKET_RESEARCH_QUEUE_URL = os.environ["MARKET_RESEARCH_QUEUE_URL"]
EXTERNAL_RESEARCH_QUEUE_URL = os.environ["EXTERNAL_RESEARCH_QUEUE_URL"]

# Get table reference
jobs_table = dynamodb.Table(JOBS_TABLE_NAME)

# --- SQS MAPPING ---
SQS_MAPPING = {
    "ADI": SLACK_QUEUE_URL,  # Internal Data Audit requires internal contact (Slack)
    "ECG": MARKET_RESEARCH_QUEUE_URL,  # External Context requires Market Research
    "VEE": EXTERNAL_RESEARCH_QUEUE_URL,  # External Experts requires External Research
}


# --- JOB SCHEMA DEFINITION ---

def get_orchestrator_job_schema():
    """
    Defines the structured output schema for the Claude model using Anthropic's job format.
    """
    return [
        {
            "name": "project_quantification_engine_output",
            "description": "The definitive, structured output containing the AI analysis and the full execution details for the ADI, ECG, and VEE research modules. This job MUST be called to provide the final answer.",
            "input_schema": {
                "type": "object",
                "properties": {
                    "analysis_ia": {
                        "type": "object",
                        "description": "Contains the summary and classification scores of the input problem.",
                        "properties": {
                            "problem_summary": {"type": "string"},
                            "full_problem_declaration": {"type": "string"},
                            "classification_scores": {
                                "type": "object",
                                "properties": {
                                    "internal_data_need": {"type": "integer", "description": "Score 1-5 for ADI need."},
                                    "external_context_need": {"type": "integer", "description": "Score 1-5 for ECG need."},
                                    "specialized_expertise_need": {"type": "integer", "description": "Score 1-5 for VEE need."}
                                }
                            }
                        },
                        "required": ["problem_summary", "full_problem_declaration", "classification_scores"]
                    },
                    "detail_execution": {
                        "type": "object",
                        "description": "Contains the detailed execution payload for the ADI, ECG, and VEE modules. The detailed structure (including 'activate' boolean and specific content) must be generated by the model based on the System Instruction.",
                        "properties": {
                            "ADI": {"type": "object"},
                            "ECG": {"type": "object"},
                            "VEE": {"type": "object"}
                        },
                        "required": ["ADI", "ECG", "VEE"]
                    }
                },
                "required": ["analysis_ia", "detail_execution"]
            }
        }
    ]

# --- SYSTEM INSTRUCTION ---

SYSTEM_INSTRUCTION = (
    "You are the Project Risk Orchestrator (PRO), an AI designed to challenge corporate inertia and validate project ideas. "
    "Your sole purpose is to analyze the completeness of the problem declaration and determine the most efficient, non-redundant research path. "
    "You operate based on three fundamental needs: Internal Data (ADI), External Context (ECG), and Specialized Expertise (VEE). "
    "Analyze the provided FULL_PROBLEM_DECLARATION and the INTERNAL_REGISTRY_DATA."

    "\n\n[1] CLASSIFICATION: Assign a score of 1 (Low) to 5 (High) for the three knowledge needs based ONLY on the input text."
    "\n[2] ACTIVATION LOGIC: Use the following thresholds to set the 'activate' boolean within each module's detail:"
    "\n   - ADI: Activate if the problem is internal, operational, or financial and requires specific company metrics (Score 4 or higher)."
    "\n   - ECG: Activate if the problem involves market trends, competitor behavior, or general industry feasibility (Score 3 or higher)."
    "\n   - VEE: Activate only if the problem is highly technical, legal, or specialized (e.g., Blockchain, AI, new regulation) requiring external validation of viability (Score 5)."

    "\n\n[3] CONTENT GENERATION: For every activated module, generate the full content details:"
    "\n   - ADI: Analyze the INTERNAL_REGISTRY_DATA to identify the most relevant people to contact. "
    "Select 2-3 specific individuals whose roles, project experience, or expertise align with the problem. "
    "For each person, include: name, email, role, justification for selection based on their projects/expertise, "
    "and 2-3 specific questions or data points to request from them."
    "\n   - ECG: Generate 3 highly specific search queries and 3 expected quantifiable data points."
    "\n   - VEE: Define the precise expert profile and generate 3 critical, high-level, challenging questions."

    "\n\nYour final output MUST be generated by calling the provided job. "
    "When selecting ADI contacts, match the problem domain to people's project history and expertise from the INTERNAL_REGISTRY_DATA."
)


# --- API UTILITY FUNCTION ---

def call_anthropic_with_jobs(system: str, user_prompt: str) -> Dict[str, Any]:
    """Makes a call to the Anthropic API using the shared module with tool execution."""
    try:
        # Create message in the required format
        messages = [ConversationMessage(
            role="user",
            content=user_prompt,
            timestamp=datetime.utcnow().isoformat()
        )]

        # Call with tools support
        result = anthropic.send_message_with_tools(
            messages=messages,
            tools=get_orchestrator_job_schema(),
            system=system
        )

        return result

    except Exception as e:
        logger.error(f"Error calling Anthropic API: {e}")
        raise


# --- MAIN HANDLER ---

def handler(event: Dict[str, Any], context: Any) -> Dict[str, Any]:
    """
    Orchestrator Lambda function that processes job requests.
    Calls Anthropic to orchestrate the research jobs, persists them to DynamoDB,
    and fans out the job records to the appropriate SQS queues.
    """
    logger.info(f"Received event: {json.dumps(event)}")

    try:
        # 1. Input Parsing and Validation
        body = event.get('body', event)
        if isinstance(body, str):
            body = json.loads(body)

        full_declaration = body.get('full_problem_declaration')

        # Always use organization diagram as internal memory (client onboarding simulation)
        organization_data = get_organization_registry()
        internal_registry = json.dumps(organization_data, indent=2) if organization_data else "No internal registry data available"

        logger.info(f"Using organization data for {len(organization_data)} people from internal registry")

        if not full_declaration:
            return {
                'statusCode': 400,
                'headers': {'Content-Type': 'application/json', 'Access-Control-Allow-Origin': '*'},
                'body': json.dumps({'error': 'Missing required parameter: full_problem_declaration'})
            }

        # 2. Construct the User Prompt Content and API Payload
        user_prompt = (
            "Analyze the following project problem declaration and the internal company registry data to generate the complete execution order.\n\n"
            "--- FULL PROBLEM DECLARATION (CONTEXT):\n"
            f"{full_declaration}\n\n"
            "--- INTERNAL REGISTRY DATA (FOR CONTACT MAPPING):\n"
            f"{internal_registry}\n\n"
            "Proceed with the 3-step analysis (Classification, Activation Logic, Content Generation) and return the output STRICTLY in the required JSON schema."
        )

        # 3. Execute the AI Orchestration
        orchestrated_result = call_anthropic_with_jobs(SYSTEM_INSTRUCTION, user_prompt)

        # 4. Job Persistence (DynamoDB) and SQS Fan-Out Execution
        triggered_jobs = []

        if not orchestrated_result or 'detail_execution' not in orchestrated_result:
            raise Exception("AI orchestration failed to return a valid execution plan.")

        detail_execution = orchestrated_result['detail_execution']
        context_summary = orchestrated_result['analysis_ia']['problem_summary']
        current_time = datetime.utcnow().isoformat()

        # We iterate over the expected keys (ADI, ECG, VEE)
        for job_key, job_payload in detail_execution.items():
            if job_payload.get('activate') is True:
                queue_url = SQS_MAPPING.get(job_key)

                if queue_url:
                    job_id = str(uuid.uuid4())

                    # A) CREATE JOB RECORD (DynamoDB Persistence)
                    job_item = {
                        'id': job_id,
                        'status': 'CREATED',
                        # Store the full, complex AI instructions as a string
                        'instructions': json.dumps(job_payload),
                        'context_summary': context_summary,
                        'type': job_key, # ADI, ECG, or VEE
                        'result': '',
                        'created_at': current_time,
                        'updated_at': current_time
                    }

                    jobs_table.put_item(Item=job_item)
                    logger.info(f"Created job {job_id} ({job_key}) in DynamoDB")

                    # B) SQS FAN-OUT: Send the job ID and type to the execution queue
                    message_body = {
                        'job_id': job_id,
                        'type': job_key,
                        # The worker Lambda will retrieve instructions from DynamoDB using the job_id
                    }

                    sqs.send_message(
                        QueueUrl=queue_url,
                        MessageBody=json.dumps(message_body)
                    )
                    logger.info(f"Sent message for job {job_id} to {job_key} queue")

                    created_job = {
                        'job_id': job_id,
                        'status': 'CREATED',
                        'instructions': job_payload
                    }
                    triggered_jobs.append(created_job)
                else:
                    logger.warning(f"Job {job_key} activated but no SQS URL found in map.")

        # 5. Return the Fan-Out Status
        response = {
            'statusCode': 200,
            'headers': {'Content-Type': 'application/json', 'Access-Control-Allow-Origin': '*'},
            'body': json.dumps({
                'message': 'Orchestration complete. Jobs persisted and fanned out to SQS queues.',
                'jobs': triggered_jobs,
                'classification_scores': orchestrated_result['analysis_ia']['classification_scores']
            })
        }
        logger.info(f"Successfully created {len(triggered_jobs)} jobs")
        return response

    except json.JSONDecodeError as e:
        logger.error(f"Invalid JSON in request body: {str(e)}")
        return {
            'statusCode': 400,
            'headers': {'Content-Type': 'application/json', 'Access-Control-Allow-Origin': '*'},
            'body': json.dumps({'error': 'Invalid JSON', 'message': str(e)})
        }
    except Exception as e:
        logger.error(f"Error processing request: {str(e)}", exc_info=True)
        return {
            'statusCode': 500,
            'headers': {'Content-Type': 'application/json', 'Access-Control-Allow-Origin': '*'},
            'body': json.dumps({'error': 'Internal server error', 'message': str(e)})
        }
